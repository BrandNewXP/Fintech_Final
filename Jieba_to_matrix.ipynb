{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#繁體中文專用字典\n",
    "jieba.set_dictionary('/Users/Kang/Downloads/dict.txt.big.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /Users/Kang/Downloads/dict.txt.big.txt ...\n",
      "Loading model from cache /var/folders/mk/shxltk6j1kj5l0br45b5kw2c0000gn/T/jieba.u660098a6e58520093b1c91286d454106.cache\n",
      "Loading model cost 1.050 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "#自定義字典對應我們的文本\n",
    "jieba.load_userdict('/Users/Kang/Desktop/my_dict.txt') # file_name 为文件类对象或自定义词典的路径\n",
    "with open('/Users/Kang/Desktop/my_dict.txt', 'r', encoding='utf8') as my:\n",
    "    my_value = my.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#自定義庭用字用以去除與文本分析不相干之關鍵字\n",
    "with open('stop_words.txt', 'r', encoding='utf8') as w:\n",
    "    stops = w.read().split('\\n') \n",
    "    stops.append('\\n')\n",
    "    stops.append('\\n\\n')\n",
    "    stops.append('\\x0c')\n",
    "    stops.append('（')\n",
    "    stops.append('）')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Mode: 我/ 来到/ 北京/ 清华/ 清华大学/ 华大/ 大学\n",
      "Default Mode: 我/ 来到/ 北京/ 清华大学\n",
      "他, 来到, 了, 网易, 杭研, 大厦\n",
      "小明, 硕士, 毕业, 于, 中国, 科学, 学院, 科学院, 中国科学院, 计算, 计算所, ，, 后, 在, 日本, 京都, 大学, 日本京都大学, 深造\n"
     ]
    }
   ],
   "source": [
    "#範例\n",
    "seg_list = jieba.cut(\"我来到北京清华大学\", cut_all=True)\n",
    "print(\"Full Mode: \" + \"/ \".join(seg_list))  # 全模式\n",
    " \n",
    "seg_list = jieba.cut(\"我来到北京清华大学\", cut_all=False)\n",
    "print(\"Default Mode: \" + \"/ \".join(seg_list))  # 精确模式\n",
    " \n",
    "seg_list = jieba.cut(\"他来到了网易杭研大厦\")  # 默认是精确模式\n",
    "print(\", \".join(seg_list))\n",
    " \n",
    "seg_list = jieba.cut_for_search(\"小明硕士毕业于中国科学院计算所，后在日本京都大学深造\")  # 搜索引擎模式\n",
    "print(\", \".join(seg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#以jieba詞性分析找出人名、地名、組織名、專有名\n",
    "def get_noun(t):\n",
    "    noun_list = []\n",
    "    word = pseg.cut(t)\n",
    "    for w in word:\n",
    "        if w.flag in [\"nr\", \"ns\", \"nt\", \"nz\"]:\n",
    "            if w.word not in noun_list:\n",
    "                noun_list.append(w.word)\n",
    "    return noun_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#藉由比對文本中出現最多次的RR，判斷本基金風險測度\n",
    "def find_risk(sort):\n",
    "    risk_dict = {'RR1' : 0, 'RR2' : 0, 'RR3' : 0, 'RR4' : 0, 'RR5' : 0}\n",
    "    for i in risk_dict.keys():\n",
    "        for j in sort:\n",
    "            if i == j[0]:\n",
    "                risk_dict[i] = j[1]         \n",
    "    return list(risk_dict.keys())[list(risk_dict.values()).index(max(risk_dict.values()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#一、將出現次數2以上且包含兩個以上字元的關鍵字留下\n",
    "#二、對於出現1次者，若出現在自定義辭典也留下\n",
    "#三、出現１次者，若屬人名、地名、專有名、組織名，也留下\n",
    "def mining(sort, t):\n",
    "    tem_list = []\n",
    "    noun_list = get_noun(t)\n",
    "    for i in sort:\n",
    "        if (i[1] >= 2) & (len(i[0]) > 1):\n",
    "            tem_list.append(i)\n",
    "        elif i[0] in my_value:\n",
    "            tem_list.append(i)\n",
    "        elif (i[0] in noun_list) & (len(i[0]) > 1):\n",
    "            tem_list.append(i)\n",
    "        else:\n",
    "            pass\n",
    "    return tem_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#處理產生出來的關鍵字，將他們丟到字典裡，之後用以生成矩陣\n",
    "def extend_dict_for_df(etf_counter, important, dict_for_df):\n",
    "    for i in range(len(important)):\n",
    "        if important[i][0] in exist_key:\n",
    "            dict_for_df[important[i][0]].append(important[i][1])\n",
    "        else:\n",
    "            dict_for_df[important[i][0]] = []\n",
    "            for j in range(etf_counter - 1):\n",
    "                dict_for_df[important[i][0]].append(0)\n",
    "            dict_for_df[important[i][0]].append(important[i][1])\n",
    "    if etf_counter > 1:\n",
    "        for k in exist_key:\n",
    "            if len(dict_for_df[k]) < etf_counter:\n",
    "                dict_for_df[k].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#要讀取的文本位置，以及所有ETF名稱list\n",
    "my_text_path = pd.read_csv('/Users/Kang/Desktop/output_path.csv', encoding = 'big5hkscs')\n",
    "ETF_name = []\n",
    "for i in range(len(my_text_path)):\n",
    "    ETF_name.append(my_text_path['0'][i][34:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_dict = {}\n",
    "dict_for_df = {}\n",
    "for etf_counter in range(1, len(my_text_path) + 1):\n",
    "#for etf_counter in range(1, 10 + 1):\n",
    "    path = my_text_path['0'][etf_counter - 1]\n",
    "    \n",
    "    #打開文本，讀取\n",
    "    with open(path, 'r') as f:\n",
    "        text = f.read()\n",
    "        text = text.replace('\\n', '')\n",
    "        text = text.replace('\\x0c', '')\n",
    "        \n",
    "        #第一步：先切詞，如不在停用字典中就列出，並將之降冪排序\n",
    "        terms = (i for i in jieba.cut(text, cut_all=False) if i not in stops)\n",
    "        ## 這個寫法很常出現在Ｃounter中，他可以排序，list每個item出現的次數。\n",
    "        my_sort = sorted(Counter(terms).items(), key=lambda x:x[1], reverse=True)\n",
    "        \n",
    "        #紀錄本基金風險測度\n",
    "        risk_dict[ETF_name[etf_counter - 1]] = find_risk(my_sort)\n",
    "        \n",
    "        #第二步：帶入先前函式，列出真正有用的關鍵字\n",
    "        important = mining(my_sort, text)\n",
    "        \n",
    "        #第三步：處理產生出來的關鍵字，將他們丟到字典裡，之後用以生成矩陣\n",
    "        exist_key = dict_for_df.keys()\n",
    "        extend_dict_for_df(etf_counter, important, dict_for_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成稀疏矩陣\n",
    "sparse_m = pd.DataFrame(dict_for_df)\n",
    "np.savetxt('/Users/Kang/Desktop/sparse_m.csv', sparse_m, fmt = '%d', delimiter = ',', header = ','.join(exist_key), encoding = 'big5hkscs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成共現矩陣\n",
    "cooccurance_m = np.dot(sparse_m.T, sparse_m)\n",
    "np.savetxt('/Users/Kang/Desktop/cooccurance_m.csv', cooccurance_m, fmt = '%d', delimiter = ',', header = ','.join(exist_key), encoding = 'big5hkscs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#輸出ETF風險測度\n",
    "risk_output = pd.DataFrame.from_dict(risk_dict, orient='index')\n",
    "risk_output.to_csv('/Users/Kang/Desktop/yuanta_ETF_risk.csv', encoding = 'big5hkscs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#為稀疏矩陣加上row name\n",
    "dg = pd.read_csv('/Users/Kang/Desktop/sparse_m.csv', encoding = 'big5hkscs')\n",
    "dg['ETF_name'] = ETF_name\n",
    "dg.set_index('ETF_name', inplace = True)\n",
    "dg.to_csv('/Users/Kang/Desktop/sparse_m_1.csv', encoding = 'big5hkscs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#為共現矩陣加上row name\n",
    "dh = pd.read_csv('/Users/Kang/Desktop/cooccurance_m.csv', encoding = 'big5hkscs')\n",
    "dh['keyword'] = dh.columns.tolist()\n",
    "dh.set_index('keyword', inplace = True)\n",
    "dh.to_csv('/Users/Kang/Desktop/cooccurance_m_1.csv', encoding = 'big5hkscs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
