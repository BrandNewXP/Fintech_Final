{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas_datareader.data as web\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Find all links to fund info \n",
    "\n",
    "driver = webdriver.Chrome('/mnt/c/Users/bryan/OneDrive/Desktop/chromedriver/chromedriver.exe')\n",
    "# driver.get('https://fund.cnyes.com/nav.aspx')\n",
    "\n",
    "# 所有元大基金\n",
    "# driver.get('http://fund.cdn.cnyes.com/nav.aspx?n=1&fundgroup=-%E5%9F%BA%E9%87%91%E9%A1%9E%E5%9E%8B-&CategoryLocal=-%E5%9F%BA%E9%87%91%E7%B5%84%E5%88%A5-&AllRegion=-%E6%8A%95%E8%B3%87%E5%8D%80%E5%9F%9F-&FundCompanyNameLocal=%E5%85%83%E5%A4%A7%E6%8A%95%E4%BF%A1&orderby=&fund=fundall&ddlindex=0,0,0,29')\n",
    "\n",
    "\n",
    "# 所有野村基金\n",
    "driver.get('http://fund.cdn.cnyes.com/nav.aspx?n=1&fundgroup=-%e5%9f%ba%e9%87%91%e9%a1%9e%e5%9e%8b-&CategoryLocal=-%e5%9f%ba%e9%87%91%e7%b5%84%e5%88%a5-&AllRegion=-%e6%8a%95%e8%b3%87%e5%8d%80%e5%9f%9f-&FundCompanyNameLocal=%e9%87%8e%e6%9d%91%e6%8a%95%e4%bf%a1&orderby=&fund=fundall&ddlindex=0,0,0,42')\n",
    "\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "links = []\n",
    "\n",
    "for i in range(10):\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "    for item in soup.find_all('a'):\n",
    "        link = item.get('href')\n",
    "        if 'detail' in str(link) and link not in links:\n",
    "            links.append(link)\n",
    "    try:\n",
    "        next_page = driver.find_element_by_id('example_next')\n",
    "        next_page.click()\n",
    "    except:\n",
    "        break\n",
    "        \n",
    "funds = [x.split('/')[2] for x in links]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(funds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 野村ｅ科技基金\n",
      "2 野村高科技基金\n",
      "3 野村中小基金-累積類型\n",
      "4 野村優質基金-累積類型新臺幣計價\n",
      "5 野村優質基金-S類型新臺幣累積\n",
      "6 野村台灣運籌基金\n",
      "7 野村鴻運基金\n",
      "8 野村積極成長基金\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "all_funds = []\n",
    "driver = webdriver.Chrome('/mnt/c/Users/bryan/OneDrive/Desktop/chromedriver/chromedriver.exe')\n",
    "\n",
    "\n",
    "for i in range(len(funds)):\n",
    "    try:\n",
    "        name = funds[i]\n",
    "        print(i + 1, name)\n",
    "        link = 'https://fund.cnyes.com' + links[i]\n",
    "        driver.get(link)\n",
    "        time.sleep(3)\n",
    "\n",
    "        content = []\n",
    "        current = '1'\n",
    "        while True:\n",
    "            page_source = driver.page_source\n",
    "            soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "            dates = []\n",
    "            for info in soup.find_all('td', {'class':'_1JRsZ'}):\n",
    "                dates.append(info.text)\n",
    "                current = info.text\n",
    "\n",
    "\n",
    "            nav = []\n",
    "            for info in soup.find_all('td', {'class':False})[-30:]:\n",
    "                if info.text != '0.00%' and info.text != '0.0000' and len(info.text)>0 and info.text[-1] != '%':\n",
    "        #             print(info.text)\n",
    "                    nav.append(info.text)\n",
    "\n",
    "            content.append(pd.DataFrame({'Date':dates, name:nav}))\n",
    "\n",
    "            try:\n",
    "                next_page = driver.find_element_by_xpath(\"//a[contains(text(),'下一頁')]\")\n",
    "                next_page.click()\n",
    "            except:\n",
    "                break\n",
    "\n",
    "            if '2016/01/04' in dates:\n",
    "                break\n",
    "\n",
    "        final = pd.concat(content)\n",
    "        final.drop_duplicates(inplace = True)\n",
    "        final.sort_values(['Date'], inplace = True)\n",
    "        final.set_index(['Date'], inplace = True)\n",
    "        all_funds.append(final)\n",
    "        save = pd.concat(all_funds, axis = 1, sort = True)\n",
    "        save.to_csv('野村基金淨值.csv')\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    \n",
    "save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
